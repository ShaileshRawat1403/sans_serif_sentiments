# Learning How to Think (In the Age of AI)

## Chapter 2: You Don’t Have a Prompt Problem — You Have a Thinking Problem

### Friction

"My prompt isn’t working."  
"ChatGPT gave a bad answer."  
"This tool isn’t smart enough."

No.  
It’s not the tool.  
It’s not the prompt.  
It’s the *thinking* behind the prompt.

People are treating AI like a vending machine:  
Insert a sentence. Expect brilliance.  
But AI doesn’t work on syntax alone.  
It works on **structure, logic, and clarity** — all things that reflect *how you think*.

---

### Bridge

Prompts are not magic spells.  
They are structured reflections of how clearly you:
- Define a problem  
- Break it down  
- Anticipate edge cases  
- Guide decisions

AI isn’t here to replace your thinking.  
It’s here to **mirror and scale it**.  
So if your thinking is scattered, shallow, or incomplete — your prompt will be too.

---

### Evidence

- A vague prompt like “Write me a strategy” leads to fluff because no inputs were defined.  
- A prompt with unclear goals like “Summarize this” without tone, length, or audience leads to generic output.  
- An overstuffed prompt with multiple instructions and no hierarchy confuses the model — and a human.

And still, people say:  
> “LLMs are dumb.”

No. They're *faithful to your ambiguity*.

---

### Implication

AI doesn’t fill in your mental gaps.  
It **magnifies** them.

Every weak prompt is a window into unstructured thought.  
Every AI hallucination is often a **human assumption** that was never clarified.

This isn’t about writing better prompts.  
It’s about **thinking better questions**.

The model isn’t failing.  
It’s following your fog.

---

### Action

Ask yourself before prompting:
- What exactly do I want?
- Who is it for?
- What is the desired format?
- What should be excluded?
- What assumptions am I making?

Then structure it like a briefing, not a magic wish:
- Objective  
- Background  
- Constraints  
- Output format  
- Evaluation criteria

You’ll notice — the AI gets sharper.  
Because *you* got sharper.

Try this:  
Take a failed prompt you used recently.  
Now answer the five questions above.  
Rewrite it like a design doc. Run it again.  
Compare. Learn. Repeat.

---

### Look Ahead

In the next chapter, we’ll go deeper into a major misconception:  
> “Agents are just tools.”

But what if they’re not?  
What if agents are **externalized thought loops**?  
Structured reflections of how you reason, decide, and act?

If so — building agents isn’t a coding task.  
It’s a thinking ritual.

> Let’s build the ritual, one loop at a time.

---

**File:** `learning-how-to-think/chapter-2-thinking-problem.md`